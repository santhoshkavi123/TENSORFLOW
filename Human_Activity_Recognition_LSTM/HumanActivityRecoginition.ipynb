{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7d281e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from typing import List, Dict\n",
    "\n",
    "# Import Required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# sklearn libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (classification_report, \n",
    "                             confusion_matrix)\n",
    "from sklearn.base import (BaseEstimator, \n",
    "                         TransformerMixin)\n",
    "\n",
    "\n",
    "# tensorflow packages\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import (Adam, \n",
    "                                         AdamW)\n",
    "from tensorflow.keras.losses import (SparseCategoricalCrossentropy,\n",
    "                                    CategoricalCrossentropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f39feea",
   "metadata": {},
   "source": [
    "# Load Dataset\n",
    "\n",
    "The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz.\n",
    "\n",
    "Basically,our objective is to create this dataset\n",
    "\n",
    "- Triaxial acceleration from the accelerometer (total acceleration) and the estimated body acceleration.\n",
    "- Triaxial Angular velocity from the gyroscope. \n",
    "- A 561-feature vector with time and frequency domain variables. \n",
    "- Its activity label. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2f2632",
   "metadata": {},
   "source": [
    "#### Step 1 : Load data captured from accelerometer and gyroscope\n",
    "- Triaxial acceleration from the accelerometer (total acceleration) and the estimated body acceleration \n",
    "- Triaxial Angular velocity from the gyroscope\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109c5d6c",
   "metadata": {},
   "source": [
    "##### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3041b947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of body_acc : (7352, 384)\n",
      "Shape of body_gyro : (7352, 384)\n",
      "Shape of total_acc : (7352, 384)\n"
     ]
    }
   ],
   "source": [
    "def load_data(filename: str) -> np.ndarray:\n",
    "    data = pd.read_csv(filename, header = None, delim_whitespace=True)\n",
    "    return data.to_numpy()\n",
    "\n",
    "\n",
    "def merge_triaxial_into_sarray(path:str, prefix_filename:str = None, type_fil:str = None) -> np.ndarray:\n",
    "    filenames = [os.path.join(path, prefix_filename + \"_\" + axial + \"_\"+ type_fil +\".txt\") for axial in ['x', 'y', 'z']]\n",
    "    \n",
    "    concated_array = np.array([])\n",
    "    for filename in filenames:\n",
    "        if concated_array.shape[0] == 0:\n",
    "            concated_array  = load_data(filename)\n",
    "        else:\n",
    "            concated_array = np.hstack((concated_array, load_data(filename)))\n",
    "\n",
    "    return concated_array\n",
    "\n",
    "\n",
    "train_path = \"./data/UCI_HAR_Dataset/train/InertialSignals/\"\n",
    "\n",
    "# Body Acceleration\n",
    "body_acc = merge_triaxial_into_sarray(path = train_path, \n",
    "                           prefix_filename= \"body_acc\",\n",
    "                           type_fil=\"train\")\n",
    "\n",
    "# Body Gyroscope\n",
    "body_gyro = merge_triaxial_into_sarray(path = train_path, \n",
    "                                       prefix_filename= \"body_gyro\",\n",
    "                                       type_fil=\"train\")\n",
    "\n",
    "# Total Acceleration\n",
    "total_acc = merge_triaxial_into_sarray(path = train_path, \n",
    "                                       prefix_filename= \"total_acc\",\n",
    "                                       type_fil=\"train\")\n",
    "\n",
    "\n",
    "print(f\"Shape of body_acc : {body_acc.shape}\")\n",
    "print(f\"Shape of body_gyro : {body_gyro.shape}\")\n",
    "print(f\"Shape of total_acc : {total_acc.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e5d10d",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1a9da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of body_acc : (2947, 384)\n",
      "Shape of body_gyro : (2947, 384)\n",
      "Shape of total_acc : (2947, 384)\n"
     ]
    }
   ],
   "source": [
    "test_path = \"./data/UCI_HAR_Dataset/test/InertialSignals/\"\n",
    "\n",
    "# Body Acceleration\n",
    "body_acc_test = merge_triaxial_into_sarray(path = test_path, \n",
    "                           prefix_filename= \"body_acc\",\n",
    "                           type_fil=\"test\")\n",
    "\n",
    "# Body Gyroscope\n",
    "body_gyro_test = merge_triaxial_into_sarray(path = test_path, \n",
    "                                       prefix_filename= \"body_gyro\",\n",
    "                                       type_fil=\"test\")\n",
    "\n",
    "# Total Acceleration\n",
    "total_acc_test = merge_triaxial_into_sarray(path = test_path, \n",
    "                                       prefix_filename= \"total_acc\",\n",
    "                                       type_fil=\"test\")\n",
    "\n",
    "\n",
    "print(f\"Shape of body_acc : {body_acc_test.shape}\")\n",
    "print(f\"Shape of body_gyro : {body_gyro_test.shape}\")\n",
    "print(f\"Shape of total_acc : {total_acc_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623f0124",
   "metadata": {},
   "source": [
    "#### Step 2 : Load 561 time and frequency domains features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32878d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train : (7352, 561)\n",
      "Shape of y_train : (7352, 1)\n",
      "Shape of X_test : (2947, 561)\n",
      "Shape of y_test : (2947, 1)\n"
     ]
    }
   ],
   "source": [
    "time_freq_train_path = \"./data/UCI_HAR_Dataset/train/\"\n",
    "time_freq_test_path = \"./data/UCI_HAR_Dataset/test\"\n",
    "\n",
    "X_train = load_data(filename= os.path.join(time_freq_train_path, \"X_train.txt\"))\n",
    "y_train = load_data(filename= os.path.join(time_freq_train_path, \"y_train.txt\"))\n",
    "X_test = load_data(filename= os.path.join(time_freq_test_path, \"X_test.txt\"))\n",
    "y_test = load_data(filename= os.path.join(time_freq_test_path, \"y_test.txt\"))\n",
    "\n",
    "print(f\"Shape of X_train : {X_train.shape}\")\n",
    "print(f\"Shape of y_train : {y_train.shape}\")\n",
    "print(f\"Shape of X_test : {X_test.shape}\")\n",
    "print(f\"Shape of y_test : {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3461bf",
   "metadata": {},
   "source": [
    "#### Step 3: Merge both the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39945f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.28858451, -0.02029417, -0.13290514, ..., -0.84124676,\n",
       "         0.17994061, -0.05862692],\n",
       "       [ 0.27841883, -0.01641057, -0.12352019, ..., -0.8447876 ,\n",
       "         0.18028889, -0.05431672],\n",
       "       [ 0.27965306, -0.01946716, -0.11346169, ..., -0.84893347,\n",
       "         0.18063731, -0.04911782],\n",
       "       ...,\n",
       "       [ 0.27338737, -0.01701062, -0.04502183, ..., -0.77913261,\n",
       "         0.24914484,  0.04081119],\n",
       "       [ 0.28965416, -0.01884304, -0.15828059, ..., -0.78518142,\n",
       "         0.24643223,  0.02533948],\n",
       "       [ 0.35150347, -0.01242312, -0.20386717, ..., -0.78326693,\n",
       "         0.24680852,  0.03669484]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2dcccd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
