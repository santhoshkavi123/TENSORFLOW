{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "816f2aaf",
   "metadata": {},
   "source": [
    "# Import Required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a15fa97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kavisanthoshkumar/Library/CloudStorage/OneDrive-IllinoisInstituteofTechnology/Tensorflow/tensorflow_env/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# tensorflow packages\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Dense, \n",
    "                                    Input, \n",
    "                                    LSTM,\n",
    "                                    Dropout)\n",
    "from tensorflow.keras.optimizers import (Adam, \n",
    "                                         AdamW)\n",
    "from tensorflow.keras.callbacks import (EarlyStopping, \n",
    "                                        ModelCheckpoint)\n",
    "from tensorflow.keras.losses import (SparseCategoricalCrossentropy,\n",
    "                                     CategoricalCrossentropy)                                         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87725d7e",
   "metadata": {},
   "source": [
    "# Load Train, Validation and Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0211b758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train : (5881, 128, 9) and Y_train : (5881, 6)\n",
      "Shape of X_val : (1471, 128, 9) and Y_train : (1471, 6)\n",
      "Shape of X_test : (2947, 128, 9) and Y_test : (2947, 6)\n"
     ]
    }
   ],
   "source": [
    "data = np.load(\"../data/processed/processed_array.npz\")\n",
    "\n",
    "X_train, y_train = data[\"x_train\"], data[\"y_train\"]\n",
    "X_test, y_test = data[\"x_test\"], data[\"y_test\"]\n",
    "X_val, y_val = data['x_val'], data[\"y_val\"]\n",
    "\n",
    "print(f\"Shape of X_train : {X_train.shape} and Y_train : {y_train.shape}\")\n",
    "print(f\"Shape of X_val : {X_val.shape} and Y_train : {y_val.shape}\")\n",
    "print(f\"Shape of X_test : {X_test.shape} and Y_test : {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d748c016",
   "metadata": {},
   "source": [
    "# Create tf.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71f91b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 21:19:58.114760: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Pro\n",
      "2025-06-26 21:19:58.114801: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 18.00 GB\n",
      "2025-06-26 21:19:58.114807: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 6.00 GB\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1750990798.114817 10228996 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1750990798.114833 10228996 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(64)\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252547b2",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a083eee0",
   "metadata": {},
   "source": [
    "#### Step -1 : Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6828bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kavisanthoshkumar/Library/CloudStorage/OneDrive-IllinoisInstituteofTechnology/Tensorflow/tensorflow_env/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "class LSTM_BaselineModel(Model):\n",
    "\n",
    "    def __init__(self, num_class):\n",
    "        super(LSTM_BaselineModel, self).__init__()\n",
    "        \n",
    "        # LSTM layer\n",
    "        self.lstm_layer_1 = LSTM(units = 100,\n",
    "                                 activation = \"tanh\",\n",
    "                                 recurrent_activation = 'sigmoid',\n",
    "                                 input_shape = (),\n",
    "                                 name = \"LSTM\")\n",
    "\n",
    "        # Dense layers\n",
    "        self.dense_layer_1 = Dense(units = 256, activation = 'leaky_relu')\n",
    "        self.dense_layer_2 = Dense(units = 128, activation = 'leaky_relu')\n",
    "\n",
    "        # output layer\n",
    "        self.output_layer = Dense(units = num_class, activation = \"softmax\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # LSTM layer\n",
    "        x = self.lstm_layer_1(inputs)\n",
    "\n",
    "        # Dense layer        \n",
    "        x = self.dense_layer_1(x)\n",
    "        x = self.dense_layer_2(x)\n",
    "\n",
    "        # Output layer\n",
    "        self.out = self.output_layer(x)\n",
    "\n",
    "        return self.out\n",
    "\n",
    "model_baseline_lstm = LSTM_BaselineModel(num_class= 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cca0ce9",
   "metadata": {},
   "source": [
    "#### Step -2 : Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96f5d73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_baseline_lstm.compile(optimizer = 'adam',\n",
    "                            loss = CategoricalCrossentropy(),\n",
    "                            metrics = [\"accuracy\", \"f1_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc73d216",
   "metadata": {},
   "source": [
    "#### Step-3 Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abc5905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor = \"val_loss\",\n",
    "    patience = 5,\n",
    "    verbose = 1, \n",
    "    restore_best_weights = True, \n",
    "    mode = 'min'\n",
    ")\n",
    "\n",
    "# Model Check Pointing\n",
    "model_check_point = ModelCheckpoint(\n",
    "    filepath = \"../model/baseline_model.keras\",\n",
    "    monitor = \"val_loss\",\n",
    "    verbose = 1,\n",
    "    save_best_only = True, \n",
    ")\n",
    "\n",
    "callbacks = [early_stopping_callback, model_check_point]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ed6b0d",
   "metadata": {},
   "source": [
    "#### Step 4 : Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60a23130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 21:19:58.615958: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4938 - f1_score: 0.4453 - loss: 1.2645\n",
      "Epoch 1: val_loss improved from inf to 0.64640, saving model to ../model/baseline_model.keras\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - accuracy: 0.4947 - f1_score: 0.4464 - loss: 1.2617 - val_accuracy: 0.7260 - val_f1_score: 0.6946 - val_loss: 0.6464\n",
      "Epoch 2/50\n",
      "\u001b[1m90/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7390 - f1_score: 0.7196 - loss: 0.6029\n",
      "Epoch 2: val_loss improved from 0.64640 to 0.43925, saving model to ../model/baseline_model.keras\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.7403 - f1_score: 0.7210 - loss: 0.6006 - val_accuracy: 0.8178 - val_f1_score: 0.8043 - val_loss: 0.4392\n",
      "Epoch 3/50\n",
      "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8625 - f1_score: 0.8579 - loss: 0.3639\n",
      "Epoch 3: val_loss improved from 0.43925 to 0.27107, saving model to ../model/baseline_model.keras\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.8628 - f1_score: 0.8583 - loss: 0.3632 - val_accuracy: 0.8960 - val_f1_score: 0.8951 - val_loss: 0.2711\n",
      "Epoch 4/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9148 - f1_score: 0.9149 - loss: 0.2210\n",
      "Epoch 4: val_loss improved from 0.27107 to 0.20780, saving model to ../model/baseline_model.keras\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9149 - f1_score: 0.9150 - loss: 0.2208 - val_accuracy: 0.9191 - val_f1_score: 0.9210 - val_loss: 0.2078\n",
      "Epoch 5/50\n",
      "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9354 - f1_score: 0.9376 - loss: 0.1611\n",
      "Epoch 5: val_loss improved from 0.20780 to 0.19451, saving model to ../model/baseline_model.keras\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9355 - f1_score: 0.9377 - loss: 0.1609 - val_accuracy: 0.9198 - val_f1_score: 0.9217 - val_loss: 0.1945\n",
      "Epoch 6/50\n",
      "\u001b[1m90/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9432 - f1_score: 0.9459 - loss: 0.1442\n",
      "Epoch 6: val_loss improved from 0.19451 to 0.15635, saving model to ../model/baseline_model.keras\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9433 - f1_score: 0.9460 - loss: 0.1440 - val_accuracy: 0.9368 - val_f1_score: 0.9396 - val_loss: 0.1563\n",
      "Epoch 7/50\n",
      "\u001b[1m90/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9458 - f1_score: 0.9488 - loss: 0.1336\n",
      "Epoch 7: val_loss improved from 0.15635 to 0.13848, saving model to ../model/baseline_model.keras\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9459 - f1_score: 0.9489 - loss: 0.1336 - val_accuracy: 0.9415 - val_f1_score: 0.9455 - val_loss: 0.1385\n",
      "Epoch 8/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9504 - f1_score: 0.9534 - loss: 0.1202\n",
      "Epoch 8: val_loss did not improve from 0.13848\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9504 - f1_score: 0.9534 - loss: 0.1202 - val_accuracy: 0.9415 - val_f1_score: 0.9451 - val_loss: 0.1385\n",
      "Epoch 9/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9485 - f1_score: 0.9516 - loss: 0.1214\n",
      "Epoch 9: val_loss improved from 0.13848 to 0.13778, saving model to ../model/baseline_model.keras\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9486 - f1_score: 0.9516 - loss: 0.1214 - val_accuracy: 0.9361 - val_f1_score: 0.9403 - val_loss: 0.1378\n",
      "Epoch 10/50\n",
      "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9524 - f1_score: 0.9554 - loss: 0.1176\n",
      "Epoch 10: val_loss did not improve from 0.13778\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9524 - f1_score: 0.9554 - loss: 0.1176 - val_accuracy: 0.9293 - val_f1_score: 0.9327 - val_loss: 0.1791\n",
      "Epoch 11/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9326 - f1_score: 0.9340 - loss: 0.1835\n",
      "Epoch 11: val_loss did not improve from 0.13778\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9327 - f1_score: 0.9341 - loss: 0.1833 - val_accuracy: 0.9313 - val_f1_score: 0.9349 - val_loss: 0.1493\n",
      "Epoch 12/50\n",
      "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9511 - f1_score: 0.9541 - loss: 0.1166\n",
      "Epoch 12: val_loss did not improve from 0.13778\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9511 - f1_score: 0.9542 - loss: 0.1167 - val_accuracy: 0.9368 - val_f1_score: 0.9406 - val_loss: 0.1467\n",
      "Epoch 13/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9507 - f1_score: 0.9536 - loss: 0.1197\n",
      "Epoch 13: val_loss improved from 0.13778 to 0.12278, saving model to ../model/baseline_model.keras\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9507 - f1_score: 0.9537 - loss: 0.1197 - val_accuracy: 0.9470 - val_f1_score: 0.9509 - val_loss: 0.1228\n",
      "Epoch 14/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9495 - f1_score: 0.9528 - loss: 0.1147\n",
      "Epoch 14: val_loss did not improve from 0.12278\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9495 - f1_score: 0.9528 - loss: 0.1147 - val_accuracy: 0.9483 - val_f1_score: 0.9523 - val_loss: 0.1230\n",
      "Epoch 15/50\n",
      "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9495 - f1_score: 0.9529 - loss: 0.1100\n",
      "Epoch 15: val_loss improved from 0.12278 to 0.11861, saving model to ../model/baseline_model.keras\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9495 - f1_score: 0.9529 - loss: 0.1101 - val_accuracy: 0.9504 - val_f1_score: 0.9543 - val_loss: 0.1186\n",
      "Epoch 16/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9503 - f1_score: 0.9536 - loss: 0.1082\n",
      "Epoch 16: val_loss did not improve from 0.11861\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9503 - f1_score: 0.9536 - loss: 0.1082 - val_accuracy: 0.9470 - val_f1_score: 0.9511 - val_loss: 0.1239\n",
      "Epoch 17/50\n",
      "\u001b[1m90/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9471 - f1_score: 0.9504 - loss: 0.1150\n",
      "Epoch 17: val_loss did not improve from 0.11861\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9471 - f1_score: 0.9504 - loss: 0.1153 - val_accuracy: 0.9436 - val_f1_score: 0.9475 - val_loss: 0.1222\n",
      "Epoch 18/50\n",
      "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9492 - f1_score: 0.9522 - loss: 0.1192\n",
      "Epoch 18: val_loss did not improve from 0.11861\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9491 - f1_score: 0.9522 - loss: 0.1193 - val_accuracy: 0.9470 - val_f1_score: 0.9509 - val_loss: 0.1303\n",
      "Epoch 19/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9486 - f1_score: 0.9515 - loss: 0.1189\n",
      "Epoch 19: val_loss did not improve from 0.11861\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9486 - f1_score: 0.9515 - loss: 0.1189 - val_accuracy: 0.9497 - val_f1_score: 0.9529 - val_loss: 0.1226\n",
      "Epoch 20/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9448 - f1_score: 0.9474 - loss: 0.1371\n",
      "Epoch 20: val_loss improved from 0.11861 to 0.11697, saving model to ../model/baseline_model.keras\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9448 - f1_score: 0.9475 - loss: 0.1369 - val_accuracy: 0.9517 - val_f1_score: 0.9552 - val_loss: 0.1170\n",
      "Epoch 21/50\n",
      "\u001b[1m90/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9512 - f1_score: 0.9542 - loss: 0.1085\n",
      "Epoch 21: val_loss improved from 0.11697 to 0.11028, saving model to ../model/baseline_model.keras\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9513 - f1_score: 0.9543 - loss: 0.1085 - val_accuracy: 0.9558 - val_f1_score: 0.9591 - val_loss: 0.1103\n",
      "Epoch 22/50\n",
      "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9531 - f1_score: 0.9563 - loss: 0.1030\n",
      "Epoch 22: val_loss did not improve from 0.11028\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9531 - f1_score: 0.9563 - loss: 0.1030 - val_accuracy: 0.9551 - val_f1_score: 0.9586 - val_loss: 0.1128\n",
      "Epoch 23/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9533 - f1_score: 0.9565 - loss: 0.1011\n",
      "Epoch 23: val_loss did not improve from 0.11028\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9533 - f1_score: 0.9565 - loss: 0.1011 - val_accuracy: 0.9551 - val_f1_score: 0.9586 - val_loss: 0.1105\n",
      "Epoch 24/50\n",
      "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9550 - f1_score: 0.9581 - loss: 0.0989\n",
      "Epoch 24: val_loss did not improve from 0.11028\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9550 - f1_score: 0.9581 - loss: 0.0990 - val_accuracy: 0.9565 - val_f1_score: 0.9598 - val_loss: 0.1110\n",
      "Epoch 25/50\n",
      "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9578 - f1_score: 0.9608 - loss: 0.0972\n",
      "Epoch 25: val_loss did not improve from 0.11028\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9577 - f1_score: 0.9607 - loss: 0.0972 - val_accuracy: 0.9579 - val_f1_score: 0.9609 - val_loss: 0.1117\n",
      "Epoch 26/50\n",
      "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9582 - f1_score: 0.9612 - loss: 0.0955\n",
      "Epoch 26: val_loss did not improve from 0.11028\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9582 - f1_score: 0.9611 - loss: 0.0955 - val_accuracy: 0.9579 - val_f1_score: 0.9609 - val_loss: 0.1134\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n"
     ]
    }
   ],
   "source": [
    "history = model_baseline_lstm.fit(train_dataset, \n",
    "                                  epochs = 50, \n",
    "                                  batch_size = 32,\n",
    "                                  validation_data = validation_dataset,\n",
    "                                  callbacks = callbacks,\n",
    "                                  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ba9fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Step"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
