{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00df0e22",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f7d281e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from typing import List, Dict\n",
    "\n",
    "# Import Required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# sklearn libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (classification_report, \n",
    "                             confusion_matrix)\n",
    "from sklearn.base import (BaseEstimator, \n",
    "                         TransformerMixin)\n",
    "\n",
    "\n",
    "# tensorflow packages\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import (Adam, \n",
    "                                         AdamW)\n",
    "from tensorflow.keras.losses import (SparseCategoricalCrossentropy,\n",
    "                                    CategoricalCrossentropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f39feea",
   "metadata": {},
   "source": [
    "# Load Dataset\n",
    "\n",
    "The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz.\n",
    "\n",
    "Basically,our objective is to create this dataset\n",
    "\n",
    "- Triaxial acceleration from the accelerometer (total acceleration) and the estimated body acceleration.\n",
    "- Triaxial Angular velocity from the gyroscope. \n",
    "- A 561-feature vector with time and frequency domain variables. \n",
    "- Its activity label. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2f2632",
   "metadata": {},
   "source": [
    "#### Step 1 : Load data captured from accelerometer and gyroscope\n",
    "- Triaxial acceleration from the accelerometer (total acceleration) and the estimated body acceleration \n",
    "- Triaxial Angular velocity from the gyroscope\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109c5d6c",
   "metadata": {},
   "source": [
    "##### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3041b947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of body_acc : (7352, 128, 3)\n",
      "Shape of body_gyro : (7352, 128, 3)\n",
      "Shape of total_acc : (7352, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "def load_data(filename: str) -> np.ndarray:\n",
    "    data = pd.read_csv(filename, header = None, delim_whitespace=True)\n",
    "    return data.to_numpy()\n",
    "\n",
    "\n",
    "def merge_triaxial_into_sarray(path:str, prefix_filename:str = None, type_fil:str = None) -> np.ndarray:\n",
    "    filenames = [os.path.join(path, prefix_filename + \"_\" + axial + \"_\"+ type_fil +\".txt\") for axial in ['x', 'y', 'z']]\n",
    "    \n",
    "    concated_array = np.array([])\n",
    "    for filename in filenames:\n",
    "        if concated_array.shape[0] == 0:\n",
    "            concated_array  = load_data(filename)\n",
    "        else:\n",
    "            concated_array = np.dstack((concated_array, load_data(filename)))\n",
    "\n",
    "    return concated_array\n",
    "\n",
    "\n",
    "train_path = \"../data/UCI_HAR_Dataset/train/InertialSignals/\"\n",
    "\n",
    "# Body Acceleration\n",
    "body_acc = merge_triaxial_into_sarray(path = train_path, \n",
    "                           prefix_filename= \"body_acc\",\n",
    "                           type_fil=\"train\")\n",
    "\n",
    "# Body Gyroscope\n",
    "body_gyro = merge_triaxial_into_sarray(path = train_path, \n",
    "                                       prefix_filename= \"body_gyro\",\n",
    "                                       type_fil=\"train\")\n",
    "\n",
    "# Total Acceleration\n",
    "total_acc = merge_triaxial_into_sarray(path = train_path, \n",
    "                                       prefix_filename= \"total_acc\",\n",
    "                                       type_fil=\"train\")\n",
    "\n",
    "\n",
    "\n",
    "# The numpy array looks like this: (samples, timesteps = 128 readings/window, features = [x, y, z])\n",
    "\n",
    "print(f\"Shape of body_acc : {body_acc.shape}\")\n",
    "print(f\"Shape of body_gyro : {body_gyro.shape}\")\n",
    "print(f\"Shape of total_acc : {total_acc.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e5d10d",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f1a9da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of body_acc_test : (2947, 128, 3)\n",
      "Shape of body_gyro_test : (2947, 128, 3)\n",
      "Shape of total_acc_test : (2947, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "test_path = \"../data/UCI_HAR_Dataset/test/InertialSignals/\"\n",
    "\n",
    "# Body Acceleration\n",
    "body_acc_test = merge_triaxial_into_sarray(path = test_path, \n",
    "                           prefix_filename= \"body_acc\",\n",
    "                           type_fil=\"test\")\n",
    "\n",
    "# Body Gyroscope\n",
    "body_gyro_test = merge_triaxial_into_sarray(path = test_path, \n",
    "                                       prefix_filename= \"body_gyro\",\n",
    "                                       type_fil=\"test\")\n",
    "\n",
    "# Total Acceleration\n",
    "total_acc_test = merge_triaxial_into_sarray(path = test_path, \n",
    "                                       prefix_filename= \"total_acc\",\n",
    "                                       type_fil=\"test\")\n",
    "\n",
    "\n",
    "print(f\"Shape of body_acc_test : {body_acc_test.shape}\")\n",
    "print(f\"Shape of body_gyro_test : {body_gyro_test.shape}\")\n",
    "print(f\"Shape of total_acc_test : {total_acc_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3461bf",
   "metadata": {},
   "source": [
    "#### Step 2: Merge body_acc, body_gyro and total_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39945f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the X_train: (7352, 128, 9)\n",
      "Shape of the X_test: (2947, 128, 9)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.concatenate((body_acc, body_gyro, total_acc), axis = 2)\n",
    "X_test = np.concatenate((body_acc_test, body_gyro_test, total_acc_test), axis = 2)\n",
    "\n",
    "print(f\"Shape of the X_train: {X_train.shape}\")\n",
    "print(f\"Shape of the X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2dcccd",
   "metadata": {},
   "source": [
    "##### Explanation Train Shape: (7352, 128, 9)\n",
    "\n",
    "- Number of Samples : 7352\n",
    "- Number of TimeSteps/Readings : 128 \n",
    "- Information recorded across body acceleration, body gyroscope and Total acceleration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6209282a",
   "metadata": {},
   "source": [
    "#### Step 3: Prepare label Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3663194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train: (7352, 1)\n",
      "Shaoe of y_test: (2947, 1)\n",
      "Shape of y_train (After Encoding): (7352, 6)\n",
      "Shaoe of y_test (After Encoding): (2947, 6)\n"
     ]
    }
   ],
   "source": [
    "y_train = load_data(filename= \"../data/UCI_HAR_Dataset/train/y_train.txt\")\n",
    "y_test = load_data(filename= \"../data/UCI_HAR_Dataset/test/y_test.txt\" )\n",
    "\n",
    "print(f\"Shape of y_train: {y_train.shape}\")\n",
    "print(f\"Shaoe of y_test: {y_test.shape}\")\n",
    "\n",
    "# For zero offset\n",
    "y_train = y_train-1\n",
    "y_test = y_test-1  \n",
    "\n",
    "# Perform One Hot Encoding on label Dataset\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "print(f\"Shape of y_train (After Encoding): {y_train.shape}\")\n",
    "print(f\"Shaoe of y_test (After Encoding): {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497ed9b1",
   "metadata": {},
   "source": [
    "#### Step 4: Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c21ecbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train : (5881, 128, 9)\n",
      "Shape of X_val : (1471, 128, 9)\n",
      "Shape of y_train : (5881, 6)\n",
      "Shape of y_test : (2947, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val =  train_test_split(X_train, y_train, train_size=0.8, random_state = 42)\n",
    "print(f\"Shape of X_train : {X_train.shape}\")\n",
    "print(f\"Shape of X_val : {X_val.shape}\")\n",
    "print(f\"Shape of y_train : {y_train.shape}\")\n",
    "print(f\"Shape of y_test : {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80ca088",
   "metadata": {},
   "source": [
    "#### Step 5: Save the numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fd0434",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\"../data/processed/processed_array.npz\", \n",
    "         x_train = X_train, \n",
    "         x_test = X_test,\n",
    "         x_val = X_val,\n",
    "         y_train = y_train,\n",
    "         y_test = y_test,\n",
    "         y_val =  y_val        \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27cd384",
   "metadata": {},
   "source": [
    "#### Step 6: Load Saved numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f0cde50",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"../data/processed/processed_array.npz\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
