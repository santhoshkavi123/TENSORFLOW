{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d56793e",
   "metadata": {},
   "source": [
    "# Import Required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9f972f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Basic Packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Dict\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# sklearn packages\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (classification_report, \n",
    "                             confusion_matrix)\n",
    "\n",
    "# tensorflow packages\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Rescaling,\n",
    "    Dense,\n",
    "    Conv2D, \n",
    "    MaxPooling2D, \n",
    "    BatchNormalization, \n",
    "    Flatten\n",
    ")\n",
    "from tensorflow.keras.optimizers import (\n",
    "    Adam, \n",
    "    RMSprop\n",
    ")\n",
    "from tensorflow.keras.losses import (\n",
    "    SparseCategoricalCrossentropy, \n",
    "    CategoricalCrossentropy\n",
    ")\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping, \n",
    "    ModelCheckpoint\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7790969",
   "metadata": {},
   "source": [
    "# Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bded83bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR = \"/Users/kavisanthoshkumar/Downloads/Sheep_Classification_Images/\"\n",
    "CSV_PATH = \"/Users/kavisanthoshkumar/Downloads/Sheep_Classification_Images/train_labels.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58a92eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>label_Encoded</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39d30b68.jpg</td>\n",
       "      <td>Naeimi</td>\n",
       "      <td>3</td>\n",
       "      <td>/Users/kavisanthoshkumar/Downloads/Sheep_Class...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4a9853bd.jpg</td>\n",
       "      <td>Goat</td>\n",
       "      <td>1</td>\n",
       "      <td>/Users/kavisanthoshkumar/Downloads/Sheep_Class...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d88facaa.jpg</td>\n",
       "      <td>Roman</td>\n",
       "      <td>5</td>\n",
       "      <td>/Users/kavisanthoshkumar/Downloads/Sheep_Class...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a3f4f4af.jpg</td>\n",
       "      <td>Roman</td>\n",
       "      <td>5</td>\n",
       "      <td>/Users/kavisanthoshkumar/Downloads/Sheep_Class...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16b31730.jpg</td>\n",
       "      <td>Naeimi</td>\n",
       "      <td>3</td>\n",
       "      <td>/Users/kavisanthoshkumar/Downloads/Sheep_Class...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       filename   label  label_Encoded  \\\n",
       "0  39d30b68.jpg  Naeimi              3   \n",
       "1  4a9853bd.jpg    Goat              1   \n",
       "2  d88facaa.jpg   Roman              5   \n",
       "3  a3f4f4af.jpg   Roman              5   \n",
       "4  16b31730.jpg  Naeimi              3   \n",
       "\n",
       "                                            filepath  \n",
       "0  /Users/kavisanthoshkumar/Downloads/Sheep_Class...  \n",
       "1  /Users/kavisanthoshkumar/Downloads/Sheep_Class...  \n",
       "2  /Users/kavisanthoshkumar/Downloads/Sheep_Class...  \n",
       "3  /Users/kavisanthoshkumar/Downloads/Sheep_Class...  \n",
       "4  /Users/kavisanthoshkumar/Downloads/Sheep_Class...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Read the CSV file using pandas\n",
    "label_dataset = pd.read_csv(CSV_PATH)\n",
    "\n",
    "#### Encode the values of the label\n",
    "le = LabelEncoder()\n",
    "le.fit(label_dataset[\"label\"].values)\n",
    "label_dataset[\"label_Encoded\"] = le.transform(label_dataset[\"label\"])\n",
    "\n",
    "#### Build the full Image Paths\n",
    "label_dataset[\"filepath\"] = label_dataset[\"filename\"].apply(lambda x : os.path.join(IMAGE_DIR, x))\n",
    "\n",
    "label_dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1e1f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>Encoded_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barbari</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Goat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harri</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naeimi</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Najdi</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Roman</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sawakni</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    labels  Encoded_labels\n",
       "0  Barbari               0\n",
       "1     Goat               1\n",
       "2    Harri               2\n",
       "3   Naeimi               3\n",
       "4    Najdi               4\n",
       "5    Roman               5\n",
       "6  Sawakni               6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"labels\":le.classes_, \"Encoded_labels\":le.transform(le.classes_)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4049c86",
   "metadata": {},
   "source": [
    "# Split the dataset into train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "862c14aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (545, 4)\n",
      "Shape of X_val: (137, 4)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val = train_test_split(label_dataset, \n",
    "                 train_size = 0.80, \n",
    "                 stratify= label_dataset['label']) \n",
    "# when we specify the stratify using class labels, then it gets split into stratified fashion\n",
    "\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of X_val: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c95ea201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_test: (144, 1)\n"
     ]
    }
   ],
   "source": [
    "X_test = pd.DataFrame({\"filename\": os.listdir(IMAGE_DIR+\"test/\")})\n",
    "print(f\"Shape of X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab2d411",
   "metadata": {},
   "source": [
    "# ImageData Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f0bb9b",
   "metadata": {},
   "source": [
    "#### 1. TrainDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95a4e403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 545 validated image filenames belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range = 20, \n",
    "    width_shift_range = 0.2, \n",
    "    shear_range = 0.2, \n",
    "    zoom_range = 0.2, \n",
    "    horizontal_flip = True, \n",
    "    vertical_flip = True\n",
    ")\n",
    "\n",
    "# flow from dataframe \n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe = X_train,\n",
    "    directory = IMAGE_DIR+str(\"train/\"),\n",
    "    x_col = \"filename\",\n",
    "    y_col = \"label\",\n",
    "    class_mode = \"categorical\",\n",
    "    target_size = (224, 224),\n",
    "    batch_size = 32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecef6ead",
   "metadata": {},
   "source": [
    "#### 2. ValidationDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "285f73e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 137 validated image filenames belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_datagen = ImageDataGenerator()\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    dataframe = X_val, \n",
    "    directory = IMAGE_DIR+\"train/\",\n",
    "    x_col = \"filename\",\n",
    "    y_col = \"label\",\n",
    "    class_model = \"categorical\",\n",
    "    target_size = (224, 224),\n",
    "    batch_size = 32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d39766e",
   "metadata": {},
   "source": [
    "#### 3. TestDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41828be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe = X_test,\n",
    "    directory = IMAGE_DIR + \"test/\",\n",
    "    x_col = \"filename\",\n",
    "    y_col = None,\n",
    "    class_mode = None,\n",
    "    target_size = (224, 224),\n",
    "    batch_size = 32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b024eb",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fbfb0f",
   "metadata": {},
   "source": [
    "#### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92b0e120",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(Model):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNNModel, self).__init__()\n",
    "\n",
    "        # layer 1\n",
    "        self.conv_layer_1 = Conv2D(filters = 64, kernel_size = 3, strides =1, activation = 'relu')\n",
    "        self.conv_layer_2 = Conv2D(filters = 128, kernel_size = 3, strides =1, activation = 'relu')\n",
    "        self.conv_layer_3 = Conv2D(filters = 128, kernel_size = 3, strides =1, activation = 'relu')\n",
    "\n",
    "        # BatchNormalization\n",
    "        self.batch_1 = BatchNormalization(axis = -1)\n",
    "        self.batch_2 = BatchNormalization(axis = -1)\n",
    "        self.batch_3 = BatchNormalization(axis = -1)\n",
    "\n",
    "        # MaxPooling layer\n",
    "        self.pooling = MaxPooling2D(pool_size = (3, 3))\n",
    "        \n",
    "        # Dense layer\n",
    "        self.dense_layer_1 = Dense(units = 256, activation =\"leaky_relu\")\n",
    "        self.dense_layer_2 = Dense(units = 256, activation =\"leaky_relu\")\n",
    "        self.dense_layer_3 = Dense(units = 128, activation =\"leaky_relu\") \n",
    "        self.dense_layer_4 = Dense(units = 64, activation =\"leaky_relu\")\n",
    "\n",
    "        # Flatten\n",
    "        self.flatten = Flatten()\n",
    "\n",
    "        # Output layer \n",
    "        self.out = Dense(units = num_classes, activation =\"softmax\")\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \n",
    "        # First Convolution Network\n",
    "        x= self.conv_layer_1(inputs)\n",
    "        x= self.batch_1(x, training = True)\n",
    "        x= self.pooling(x)\n",
    "        \n",
    "\n",
    "        # Second Convolution Network\n",
    "        x= self.conv_layer_2(x)\n",
    "        x= self.batch_2(x, training = True)\n",
    "        x= self.pooling(x)\n",
    "\n",
    "\n",
    "        # Second Convolution Network\n",
    "        x= self.conv_layer_3(x)\n",
    "        x= self.batch_3(x, training = True)\n",
    "        x= self.pooling(x)\n",
    "        \n",
    "\n",
    "        # Flatten\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        # Dense layers\n",
    "        x = self.dense_layer_1(x) \n",
    "        x = self.dense_layer_2(x)\n",
    "        x = self.dense_layer_3(x)\n",
    "        x = self.dense_layer_4(x)\n",
    "\n",
    "        return self.out(x)\n",
    "    \n",
    "cnn_basic_model = CNNModel(num_classes=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ec72a6",
   "metadata": {},
   "source": [
    "#### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c009d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-21 20:52:58.414359: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Pro\n",
      "2025-06-21 20:52:58.414381: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 18.00 GB\n",
      "2025-06-21 20:52:58.414386: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 6.00 GB\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1750557178.414396 7970486 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1750557178.414411 7970486 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "cnn_basic_model.compile(optimizer= Adam(), \n",
    "                        loss = CategoricalCrossentropy(),\n",
    "                        metrics = ['f1_score'],\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a797706",
   "metadata": {},
   "source": [
    "#### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1df568dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping_callback = EarlyStopping(\n",
    "    monitor = \"val_loss\",\n",
    "    patience = 5, \n",
    "    mode = \"min\",\n",
    "    restore_best_weights = True, \n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "model_check_point_callback = ModelCheckpoint(\n",
    "    filepath = \"./artifacts/cnn_basic_model.keras\",\n",
    "    monitor = \"val_loss\",\n",
    "    mode = \"min\",\n",
    "    save_best_only = True, \n",
    ")\n",
    "\n",
    "callbacks = [earlystopping_callback, model_check_point_callback]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ed4925",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55a1a233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 228ms/step - f1_score: 0.5868 - loss: 0.9517 - val_f1_score: 0.5597 - val_loss: 1.0090\n",
      "Epoch 2/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 224ms/step - f1_score: 0.5975 - loss: 0.8919 - val_f1_score: 0.5493 - val_loss: 0.9798\n",
      "Epoch 3/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 222ms/step - f1_score: 0.6541 - loss: 0.7796 - val_f1_score: 0.6031 - val_loss: 1.0339\n",
      "Epoch 4/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 222ms/step - f1_score: 0.6771 - loss: 0.7798 - val_f1_score: 0.5625 - val_loss: 1.0808\n",
      "Epoch 5/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 224ms/step - f1_score: 0.6476 - loss: 0.7545 - val_f1_score: 0.5420 - val_loss: 1.2891\n",
      "Epoch 6/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 215ms/step - f1_score: 0.6284 - loss: 0.8030 - val_f1_score: 0.5453 - val_loss: 1.0620\n",
      "Epoch 7/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 221ms/step - f1_score: 0.6498 - loss: 0.7567 - val_f1_score: 0.5287 - val_loss: 1.2258\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n"
     ]
    }
   ],
   "source": [
    "history = cnn_basic_model.fit(train_generator, \n",
    "                    epochs = 20,\n",
    "                    validation_data = validation_generator,\n",
    "                    callbacks = callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be31f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating Predictions \n",
    "predictions = cnn_basic_model.predict(test_generator, verbose = 0)\n",
    "predictions = np.argmax(predictions, axis = 1)\n",
    "\n",
    "# Submission format\n",
    "X_test[\"label\"] = predictions\n",
    "class_indices = {v:k for k, v in train_generator.class_indices.items()}\n",
    "X_test[\"label\"] = X_test[\"label\"].map(class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e28a164f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv(\"./data/output/Submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4cd6a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
